{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1offwWqu7jw6qz7xahDtPo8tyR5F4R_g-",
      "authorship_tag": "ABX9TyNwFPSKrKlcgVyoWTOWNxtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cristoffersantoro/gemini-crud-generator/blob/main/Crud_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando os pacotes necessários"
      ],
      "metadata": {
        "id": "qKFzZuZm1IAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U PyGithub\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install -q -U firebase-admin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOP76AcC3k1k",
        "outputId": "72b406cb-c86f-4239-b69d-383555b15427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando as dependências"
      ],
      "metadata": {
        "id": "sPX33Dj6YORA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "import json\n",
        "from google.colab import drive\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n"
      ],
      "metadata": {
        "id": "7lyL7DqO0en4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montando o Google Drive"
      ],
      "metadata": {
        "id": "l5UQhKGdYRy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ePZ-SLa-_A6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtendo as credenciais que serão usadas no projeto"
      ],
      "metadata": {
        "id": "mav4fx6IYXK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "caminho_arquivo = '/content/drive/MyDrive/tokens.json'  # Substitua pelo caminho correto\n",
        "\n",
        "with open(caminho_arquivo, 'r') as f:\n",
        "    dados = json.load(f)\n",
        "\n",
        "cred = credentials.Certificate('/content/drive/MyDrive/chat-gemini-firebase.json')\n",
        "git_token = dados['github-token']\n",
        "generative_ai_key = dados['generative-api-key']\n",
        "git_user = \"cristoffersantoro\"\n",
        "git_repo = \"full-stack-fastapi-template\"\n",
        "git_dir_frontend = \"frontend/src\" # Opcional\n",
        "git_dir_backend = \"backend\" # Opcional\n"
      ],
      "metadata": {
        "id": "T8BR0eCyhoOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autenticando no Firebase"
      ],
      "metadata": {
        "id": "Meoxf3YaY8xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_admin.initialize_app(cred)"
      ],
      "metadata": {
        "id": "JjFges2d_X1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autenticando no Generative AI"
      ],
      "metadata": {
        "id": "y9O4492IZB1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=generative_ai_key)"
      ],
      "metadata": {
        "id": "aH43OJcYDf9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o Modelo do Generative AI"
      ],
      "metadata": {
        "id": "zD75Z_bTZGKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.0\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config)"
      ],
      "metadata": {
        "id": "lC92cHSvDx1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métodos para listagem de arquivos no Github"
      ],
      "metadata": {
        "id": "UNSzReN5ZLSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from github import Github\n",
        "\n",
        "def listar_e_ler_arquivos_recursivamente(token, usuario, repositorio, caminho_diretorio=\"\"):\n",
        "  \"\"\"\n",
        "  Lista recursivamente os arquivos em um repositório do GitHub e lê seu conteúdo.\n",
        "\n",
        "  Args:\n",
        "    token: O token de acesso pessoal do GitHub.\n",
        "    usuario: O nome de usuário do proprietário do repositório.\n",
        "    repositorio: O nome do repositório.\n",
        "    caminho_diretorio: O caminho para o diretório (opcional).\n",
        "\n",
        "  Returns:\n",
        "    Um dicionário onde as chaves são os caminhos dos arquivos e os valores são os conteúdos dos arquivos.\n",
        "  \"\"\"\n",
        "  # Criar um objeto Github com o token\n",
        "  g = Github(token)\n",
        "\n",
        "  # Obter o repositório\n",
        "  repo = g.get_repo(f\"{usuario}/{repositorio}\")\n",
        "\n",
        "  # Obter o conteúdo do diretório\n",
        "  conteudo = repo.get_contents(caminho_diretorio)\n",
        "\n",
        "  # Listar arquivos e ler conteúdo recursivamente\n",
        "  arquivos_conteudo = {}\n",
        "  while conteudo:\n",
        "    arquivo_conteudo = conteudo.pop(0)\n",
        "    if arquivo_conteudo.type == \"dir\":\n",
        "      conteudo.extend(repo.get_contents(arquivo_conteudo.path))\n",
        "    else:\n",
        "      # Obter conteúdo do arquivo\n",
        "      conteudo_bruto = arquivo_conteudo.decoded_content\n",
        "      conteudo_texto = conteudo_bruto.decode(\"utf-8\", errors=\"ignore\")\n",
        "      arquivos_conteudo[arquivo_conteudo.path] = conteudo_texto\n",
        "\n",
        "  return arquivos_conteudo\n",
        "\n",
        "def listar_e_ler_arquivo(token, usuario, repositorio, arquivos_conteudo, caminho_arquivo):\n",
        "  \"\"\"\n",
        "  Lista recursivamente os arquivos em um repositório do GitHub e lê seu conteúdo.\n",
        "\n",
        "  Args:\n",
        "    token: O token de acesso pessoal do GitHub.\n",
        "    usuario: O nome de usuário do proprietário do repositório.\n",
        "    repositorio: O nome do repositório.\n",
        "    arquivos_conteudo: Um dicionário onde as chaves são os caminhos dos arquivos e os valores são os conteúdos dos arquivos.\n",
        "    caminho_arquivo: O caminho para o arquivo.\n",
        "\n",
        "  Returns:\n",
        "    Um dicionário onde as chaves são os caminhos dos arquivos e os valores são os conteúdos dos arquivos.\n",
        "  \"\"\"\n",
        "  # Criar um objeto Github com o token\n",
        "  g = Github(token)\n",
        "\n",
        "  # Obter o repositório\n",
        "  repo = g.get_repo(f\"{usuario}/{repositorio}\")\n",
        "\n",
        "  # Obter o conteúdo do diretório\n",
        "  conteudo = repo.get_contents(caminho_arquivo)\n",
        "\n",
        "  conteudo_bruto = conteudo.decoded_content\n",
        "  conteudo_texto = conteudo_bruto.decode(\"utf-8\", errors=\"ignore\")\n",
        "  arquivos_conteudo[conteudo.path] = conteudo_texto\n",
        "\n",
        "  return arquivos_conteudo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8-mgLhvG6PsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lista conteúdo arquivos Frontend do repositório Github"
      ],
      "metadata": {
        "id": "xQrQORlCiqAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "arquivos_conteudo_frontend = listar_e_ler_arquivos_recursivamente(git_token, git_user, git_repo, git_dir_frontend)\n",
        "arquivos_conteudo_frontend = listar_e_ler_arquivo(git_token, git_user, git_repo, arquivos_conteudo_frontend, \"frontend/README.md\")\n"
      ],
      "metadata": {
        "id": "Hnb9V5znispD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialização do Database do Firebase"
      ],
      "metadata": {
        "id": "BaITt6wsZX3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = firestore.client()"
      ],
      "metadata": {
        "id": "Kf8OJPV1FOYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salva os dados obtidos do Github no firebase. Com isso evita a necessidade de ficar usando a API do Github que possui limites de requisição"
      ],
      "metadata": {
        "id": "4XjfQyh6Ze-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "usuarios_ref = db.collection('model')\n",
        "\n",
        "for caminho, conteudo in arquivos_conteudo_frontend.items():\n",
        "  dados = {\n",
        "    'file': {\n",
        "        'path': caminho,\n",
        "        'content': conteudo\n",
        "    }\n",
        "  }\n",
        "\n",
        "  usuarios_ref.add(dados)\n",
        "\n"
      ],
      "metadata": {
        "id": "MreMfVa5Ce41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lista os arquivos salvos no Firebase que irão compor a mensagem enviada ao Chat do Gemini AI"
      ],
      "metadata": {
        "id": "XMm8_tP3Z8PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Referência à collection\n",
        "usuarios_ref = db.collection('model')\n",
        "\n",
        "# Obtendo todos os documentos\n",
        "docs = usuarios_ref.stream()\n",
        "\n",
        "for doc in docs:\n",
        "    print(f'{doc.id} => {doc.to_dict()}')"
      ],
      "metadata": {
        "id": "m_z5xynUGgzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparando o modelo de chat para receber os inputs"
      ],
      "metadata": {
        "id": "9gkHuKhvfngd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "M2K1vWxVLP2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Envia o input introdutório"
      ],
      "metadata": {
        "id": "aR7iEngaZvPK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1av_njcvLRKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trecho para enviar mensagem via Chat para o Gemini AI com retry de 3 tentativas para o caso de falha."
      ],
      "metadata": {
        "id": "Ip1ky8oYZyT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_tentativas = 3"
      ],
      "metadata": {
        "id": "s9xM3aYiQHz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enviar_mensagem_chat(mensagem, tentativa):\n",
        "  if tentativa > max_tentativas:\n",
        "    return\n",
        "  time.sleep(5)\n",
        "  try:\n",
        "    chat.send_message(mensagem)\n",
        "  except:\n",
        "    print(f\"tentativa {tentativa} falhou. Tentando novamente...\")\n",
        "    enviar_mensagem_chat(mensagem, tentativa+1)"
      ],
      "metadata": {
        "id": "Sr0uVDStOxQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Core da aplicação. Este ponto é responsável por orquestrar todo o conteúdo para o Gemini AI e usando o few-shots, irá treinar o modelo para responder\n",
        "aquilo que preciso."
      ],
      "metadata": {
        "id": "_cx5f5k8aYEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input introdutório\n",
        "chat.send_message(\"Analise os arquivos contidos nesse template react com chackra-ui. Enviarei cada arquivo separadamente para analise\")\n",
        "\n",
        "# Referência à collection\n",
        "usuarios_ref = db.collection('model')\n",
        "\n",
        "# Obtendo todos os documentos\n",
        "docs = usuarios_ref.stream()\n",
        "\n",
        "for doc in docs:\n",
        "  doc_dict = doc.to_dict()\n",
        "  print(f\"enviando o arquivo: {doc_dict['file']['path']}\")\n",
        "  enviar_mensagem_chat(f\"filepath: {doc_dict['file']['path']}, content: {doc_dict['file']['content']}\", 1)\n",
        "\n",
        "response = chat.send_message(\"\"\"\n",
        "input: analise o content do filepath frontend/README.MD\"\n",
        "input: analise a estrutura do content do filepath frontend/src/routes/_layout/items.tsx\n",
        "input: Com base na estrurura passada, explique para mim como foi\n",
        "construída a page de items, explicando cada referência, onde as rotas foram adicionadas, quais componentes e models foram criados,\n",
        "quais propriedades existem\"\"\")\n"
      ],
      "metadata": {
        "id": "o9o2diyq_5hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por conta de erros de timeout na comunicação com o Gemini AI, optei por registrar o histórico de chat no banco de dados, para posteriormente continuar\n",
        "sem precisar fazer todo um reprocessamento."
      ],
      "metadata": {
        "id": "buJMQYqFa1ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_ref = db.collection('chat-history')\n",
        "history_ref.add({'history': str(chat.history)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrc5tUu4S6r6",
        "outputId": "b803ce7d-0bb6-4e70-8202-1a166567faf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DatetimeWithNanoseconds(2024, 5, 11, 15, 32, 58, 699702, tzinfo=datetime.timezone.utc),\n",
              " <google.cloud.firestore_v1.document.DocumentReference at 0x7d78d462a620>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Responsável por resgatar o histórico salvo"
      ],
      "metadata": {
        "id": "owF-AQC0bAjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Referência à collection\n",
        "history_ref = db.collection('chat-history')\n",
        "\n",
        "query = history_ref.limit(1)\n",
        "history_docs = query.stream()\n",
        "\n",
        "for history_doc in history_docs:\n",
        "  string_lista = history_doc.to_dict()['history']\n",
        "  string_json = json.dumps(string_lista)\n",
        "  lista_convertida = json.loads(string_json)\n",
        "\n",
        "chat.history = lista_convertida\n"
      ],
      "metadata": {
        "id": "jRZxY9VZUz1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt final, onde com base no que foi treinado acima, deverá retornar o output esperado. Precisa ser refinado."
      ],
      "metadata": {
        "id": "E99yyiQtbEkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat.send_message(\"\"\"\n",
        "  Agora baseado em toda a análise feita, gostaria que gerasse para mim uma nova tela com o nome de Produtos,\n",
        "  que contém os campos Name, Description e Quantity, e seguindo o mesmo modelo da tela de Items, gere para mim todas\n",
        "  as telas e componentes necessários para nova tela, exemplo: AddProduct, EditProdut, _Layout, etc, e atualize os arquivos existentes\n",
        "  no projeto que são necessários, como routes, components, etc\n",
        "                  \"\"\")"
      ],
      "metadata": {
        "id": "-h5M8XKkgZBs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}